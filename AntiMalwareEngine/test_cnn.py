'''
@Description: testing a CNN
@Version: 1.2.2.20200413
@Author: Robin Nix and Jian Zhang
@Date: 2020-02-22 14:12:59
@Last Editors: Jichen Zhao
@LastEditTime: 2020-04-13 22:04:28
'''

import numpy as np
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # disable printing Tensorflow debugging messages with the level INFO
import tensorflow as tf

from cnn_ops import conv_net, get_one_hot_vector
from data_reader import load_test_data
from decompressor import decompress
from logger import Logger
from path_loader import get_cnn_trainer_saver_path


data_X, data_Y = load_test_data()

learning_rate = 0.00001
batch_size = 2
dimension_count = data_X.max() + 10
input_size = 50
class_count = 2 

X = tf.placeholder(tf.float32, [None, input_size, dimension_count, 1])
Y = tf.placeholder(tf.float32, [None, class_count])

# build the net and define the loss and optimiser
prediction = conv_net(X)
loss_op = tf.contrib.slim.losses.softmax_cross_entropy(prediction, Y) # use "slim" to make defining, training, and evaluating a CNN simple
training_op = tf.train.AdagradOptimizer(learning_rate = learning_rate).minimize(loss_op)

# evaluate the model
correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init_op = tf.global_variables_initializer() # intialise the variables to assign their default values

saver = tf.train.Saver()
log = Logger(os.path.basename(__file__), __name__) # initialise a logger

with tf.Session() as session:
    session.run(init_op)
    
    from tensorflow import pywrap_tensorflow # TODO:
    reader = pywrap_tensorflow.NewCheckpointReader(get_cnn_trainer_saver_path())
    print(reader.get_variable_to_shape_map())

    saver.restore(session, get_cnn_trainer_saver_path())

    batch_count = int(data_X.shape[0] / batch_size)
    batch_accuracy_sum = 0.0

    for step in range(batch_count):
        batch_x, batch_y = data_X[step * batch_size : (step + 1) * batch_size], data_Y[step * batch_size : (step + 1) * batch_size]

        batch_x = decompress(batch_x, dimension_count)
        batch_x = session.run(X, feed_dict = {X: batch_x})
        batch_y = get_one_hot_vector(batch_size, batch_y)
        batch_y = np.repeat(batch_y, input_size, axis = 0)
        assert(batch_x.shape[0] == batch_y.shape[0]) # raise exception if they have different sizes

        batch_accuracy = session.run(accuracy, feed_dict = {X: batch_x, Y: batch_y}) # calculate batch accuracy
        batch_accuracy_sum += batch_accuracy
        log.i('Step: ' + str(step), 'batch accuracy: ' + '{:.3f}'.format(batch_accuracy))

    log.i('Mean accuracy: ' + '{:.3f}'.format(batch_accuracy_sum / batch_count))