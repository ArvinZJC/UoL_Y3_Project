'''
@Description: training a CNN
@Version: 1.2.2.20200413
@Author: Robin Nix and Jian Zhang
@Date: 2020-02-22 14:12:51
@Last Editors: Jichen Zhao
@LastEditTime: 2020-04-13 22:11:51
'''

import numpy as np
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # disable printing Tensorflow debugging messages with the level INFO
import tensorflow as tf
import matplotlib.pyplot as plt

from cnn_ops import conv_net, get_one_hot_vector
from data_reader import load_training_data
from decompressor import decompress
from logger import Logger
from path_loader import get_cnn_trainer_saver_path, get_data_directory


data_X, data_Y = load_training_data()

learning_rate = 0.00001
epoch_count = 1
batch_size = 2
dimension_count = data_X.max() + 10
input_size = 50
class_count = 2

X = tf.placeholder(tf.float32, [None, input_size, dimension_count, 1])
Y = tf.placeholder(tf.float32, [None, class_count])

# build the net and define the loss and optimiser
prediction = conv_net(X)
loss_op = tf.contrib.slim.losses.softmax_cross_entropy(prediction, Y) # use "slim" to make defining, training, and evaluating a CNN simple
training_op = tf.train.AdagradOptimizer(learning_rate = learning_rate).minimize(loss_op)

# evaluate the model
correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init_op = tf.global_variables_initializer() # intialise the variables to assign their default values

saver = tf.train.Saver(max_to_keep = 1)
log = Logger(os.path.basename(__file__), __name__) # initialise a logger

with tf.Session() as session:
    session.run(init_op)

    epoch_loss_array = np.zeros([epoch_count])
    epoch_accuracy_array = np.zeros([epoch_count])
    batch_count = int(data_X.shape[0] / batch_size) # the number of iterations of each epoch

    for epoch in range(epoch_count):
        # shuffle data
        indices = np.random.permutation(np.arange(data_X.shape[0]))
        data_X = data_X[indices, :, :]
        data_Y = data_Y[indices]
        
        batch_loss_array = np.zeros([batch_count])
        batch_accuracy_array = np.zeros([batch_count])
        batch_loss_sum = 0.0
        batch_accuracy_sum = 0.0

        log.i('******************** Epoch ' + str(epoch + 1))

        for step in range(batch_count):
            batch_x, batch_y = data_X[step * batch_size : (step + 1) * batch_size], data_Y[step * batch_size : (step + 1) * batch_size]

            batch_x = decompress(batch_x, dimension_count)
            batch_x = session.run(X, feed_dict = {X: batch_x})
            batch_y = get_one_hot_vector(batch_size, batch_y)
            batch_y = np.repeat(batch_y, input_size, axis = 0)
            assert(batch_x.shape[0] == batch_y.shape[0]) # raise exception if they have different sizes
            session.run(training_op, feed_dict = {X: batch_x, Y: batch_y})
            
            batch_loss, batch_accuracy = session.run([loss_op, accuracy], feed_dict = {X: batch_x, Y: batch_y}) # calculate batch loss and accuracy
            batch_loss_array[step] = batch_loss
            batch_accuracy_array[step] = batch_accuracy
            batch_loss_sum += batch_loss
            batch_accuracy_sum += batch_accuracy
            log.i('Step ' + str(step + 1)
                + ' - loss: ' + '{:.4f}'.format(batch_loss)
                + ', accuracy: ' + '{:.3f}'.format(batch_accuracy))
        
        _, axis_batch_loss = plt.subplots()
        axis_batch_accuracy = axis_batch_loss.twinx()
        axis_batch_loss.plot(np.arange(batch_count), batch_loss_array, 'g-')
        axis_batch_accuracy.plot(np.arange(batch_count), batch_accuracy_array, 'b-')

        axis_batch_loss.set_xlabel('step')
        axis_batch_loss.set_ylabel('loss', 'g')
        axis_batch_accuracy.set_ylabel('accuracy', 'b')

        plt.show()

        epoch_loss = batch_loss_sum / batch_count
        epoch_accuracy = batch_accuracy_sum / batch_count
        epoch_loss_array[epoch] = epoch_loss
        epoch_accuracy_array[epoch] = epoch_accuracy
        log.i('(Mean loss: ' + '{:.4f}'.format(epoch_loss) + ', mean accuracy: ' + '{:.3f})'.format(epoch_accuracy))
    
    saver.save(session, get_cnn_trainer_saver_path())

    if epoch_count > 1:
        log.i('********************')
        
        _, axis_epoch_loss = plt.subplots()
        axis_epoch_accuracy = axis_epoch_loss.twinx()
        axis_epoch_loss.plot(np.arange(epoch_count), epoch_loss_array, 'g-')
        axis_epoch_accuracy.plot(np.arange(epoch_count), epoch_accuracy_array, 'b-')

        axis_epoch_loss.set_xlabel('epoch')
        axis_epoch_loss.set_ylabel('mean loss', color = 'g')
        axis_epoch_accuracy.set_ylabel('mean accuracy', color = 'b')

        plt.show()