'''
@Description: a data reader
@Version: 1.2.6.20200401
@Author: Robin Nix and Jian Zhang
@Date: 2020-02-20 20:43:42
@Last Editors: Jichen Zhao
@LastEditTime: 2020-04-08 14:39:55
'''

import numpy as np
import os
import pickle

from path_loader import get_compressed_features_directories, get_test_set_directory


def load_training_data():
    '''
    Load all pickled features for training.

    Returns
    -------
    training_X : part X of the training data

    training_Y : part Y of the training data
    '''

    X = []
    Y = []
    compressed_features_directories = get_compressed_features_directories()

    for path in os.listdir(compressed_features_directories[0]):
        data_point = pickle.load(open(os.path.join(compressed_features_directories[0], path), 'rb'), encoding = 'latin1') # change the encoding if there is a UnicodeDecodeError
        X.append(data_point['x'])
        Y.append(data_point['y'])

    for path in os.listdir(compressed_features_directories[1]):
        data_point = pickle.load(open(os.path.join(compressed_features_directories[1], path), 'rb'), encoding = 'latin1') # change the encoding if there is a UnicodeDecodeError
        X.append(data_point['x'])
        Y.append(data_point['y'])

    return np.asarray(X), np.asarray(Y)


def load_test_data():
    '''
    Load all pickled features for testing.

    Returns
    -------
    test_X : part X of the test data

    test_Y : part Y of the test data
    '''

    X = []
    Y = []
    test_set_directory = get_test_set_directory()

    for path in os.listdir(test_set_directory):
        data_point = pickle.load(open(os.path.join(test_set_directory, path), 'rb'), encoding = 'latin1') # change the encoding if there is a UnicodeDecodeError
        X.append(data_point['x'])
        Y.append(data_point['y'])

    return np.asarray(X), np.asarray(Y)


# test purposes only
if __name__ == '__main__':
    from logger import Logger
    
    
    log = Logger(os.path.basename(__file__), __name__) # initialise a logger

    training_X, training_Y = load_training_data()
    log.i('Amount of training data in part X: ' + str(len(training_X)))
    log.i('Amount of training data in part Y: ' + str(len(training_Y)))
    log.i('Number of labels in training data: ' + str(training_X.max() + 1)) # the number of labels influences the number of dimensions in the parts related to CNN

    test_X, test_Y = load_test_data()
    log.i('Amount of test data in part X: ' + str(len(test_X)))
    log.i('Amount of test data in part Y: ' + str(len(test_Y)))
    log.i('Number of labels in test data: ' + str(test_X.max() + 1))