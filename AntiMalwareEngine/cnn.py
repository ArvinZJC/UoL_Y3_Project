'''
@Description: TODO:
@Version: 1.0.1.20200222
@Author: Arvin Zhao
@Date: 2020-02-21 13:14:15
@Last Editors: Arvin Zhao
@LastEditTime: 2020-02-22 21:30:19
'''

import numpy as np
import os
import tensorflow as tf

from data_reader import load_data
from decompressor import decompress


slim = tf.contrib.slim


def lrelu(alpha):
    '''
    TODO:
    '''

    def op(inputs):
        '''
        TODO:
        '''

        return tf.maximum(inputs * alpha, inputs, name = 'leaky_relu')
    
    return op


def conv_net(input):
    '''
    TODO:
    '''

    with slim.arg_scope([slim.conv2d, slim.fully_connected],
        activation_fn = lrelu(0.005),
        weights_initializer = tf.truncated_normal_initializer(0.0, 0.01),
        weights_regularizer = slim.l2_regularizer(0.0005)): # using the scope to avoid mentioning the parameters repeatedly
        net = slim.conv2d(input, 512, (3, 86796), 1, padding = 'valid', scope = 'conv_1') # TODO: cnn2.py; if any problem, use uppercase in padding
        # net = slim.conv2d(input, 512, (5, 86796), 1, padding = 'same', scope = 'conv_1) # TODO: cnn3.py
        net = slim.max_pool2d(net, (4, 1), 4, padding = 'valid', scope = 'pool_2')
        net = slim.conv2d(net, 512, (5, 1), 1, scope = 'conv_3')
        net = slim.max_pool2d(net, (4, 1), 4, padding = 'valid', scope = 'pool_4')
        net = slim.flatten(net, scope = 'flatten_5')
    
    net = slim.fully_connected(net, 4096, scope = 'fc5')
    net = slim.dropout(net, 0.5, scope = 'dropout6')
    net = slim.fully_connected(net, 4096, scope = 'fc7')
    net = slim.dropout(net, 0.5, scope = 'dropout8')
    net = slim.fully_connected(net, 2, activation_fn = None, scope = 'fc9')

    return net


def one_hot(batch_size, Y):
    '''
    TODO:
    '''

    B = np.zeros((batch_size, 2))
    B[np.range(batch_size), Y] = 1

    return B


# test purposes only
if __name__ == '__main__':
    os.environ['CUDA_VISIBLE_DEVICES'] = '' # TODO: no this code in cnn3.py
    learning_rate = 0.00001
    num_epoch = 5
    batch_size = 2
    display_step = 1
    input_size = 50
    num_classes = 2
    
    X = tf.placeholder(tf.float32, [None, input_size, 86796, 1])
    Y = tf.placeholder(tf.float32, [None, num_classes])
    prediction = conv_net(X)
    loss_op = slim.losses.softmax_cross_entropy(prediction, Y)
    tf.summary.scalar('loss', loss_op)
    optimiser = tf.train.AdagradOptimizer(learning_rate = learning_rate)
    train_op = optimiser.minimize(loss_op)

    # evaluate the model
    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    tf.summary.scalar('accuracy', accuracy)

    # initialise the variables (i.e. assign their default value)
    init = tf.global_variables_initializer()
    data_X, data_Y = load_data()
    indices = np.random.permutation(np.arange(data_X.shape[0]))
    data_X = data_X[indices, :, :]
    data_Y = data_Y[indices]

    merged = tf.summary.merge_all()
    saver = tf.train.Saver()

    with tf.Session() as sess:
        train_writer = tf.summary.FileWriter('cnn_logs_6/', sess.graph) # TODO: cnn2.py
        # train_writer = tf.summary.FileWriter('cnn_logs_8/', sess.graph) # TODO: cnn3.py
        sess.run(init)

        i = 0

        for epoch in range(num_epoch):
            for step in range(data_X.shape[0] / batch_size):
                batch_x, batch_y = data_X[step * batch_size : (step + 1) * batch_size], data_Y[step * batch_size : (step + 1) * batch_size]
                batch_x = decompress(batch_x, 86796)
                batch_y = one_hot(batch_size, batch_y)
                batch_y = np.repeat(batch_y, 50, axis = 0)
                assert(batch_x.shape[0] == batch_y.shape[0])

                _, summary = sess.run([train_op, merged], feed_dict = {X: batch_x, Y: batch_y})
                train_writer.add_summary(summary, i)

                if step % display_step == 0:
                    loss, acc, summary = sess.run([loss_op, accuracy, merged], feed_dict = {X: batch_x, Y: batch_y}) # calculate the batch loss and accuracy

                if i % 20 == 0:
                    save_path = saver.save(sess, os.path.join('cnn_logs_6', 'epoch' + str(epoch) + 'i' + str(i) + '.ckpt')) # TODO: cnn2.py
                    # save_path = saver.save(sess, os.path.join('cnn_logs_8', 'epoch' + str(epoch) + 'i' + str(i) + '.ckpt')) # TODO: cnn3.py
                
                i += 1