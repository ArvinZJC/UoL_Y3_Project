'''
@Description: a compressed feature extractor
@Version: 1.1.0.20200322
@Author: Arvin Zhao
@Date: 2020-02-20 19:01:12
@Last Editors: Arvin Zhao
@LastEditTime: 2020-03-22 16:01:45
'''

from androguard.core.analysis import analysis
from androguard.core.bytecodes import apk, dvm
import numpy as np
import os
import pickle
import re
import sys

from logger import Logger
from path_loader import get_dictionary_path, get_malware_directory, get_compressed_features_directories # , get_benign_apps_directory


max_calls = 50


def extract_compressed_features():
    '''
    Extract compressed features for apps in the specified dataset and pickle them.
    '''

    log = Logger(os.path.basename(__file__), sys._getframe().f_code.co_name) # initialise a logger

    api_call_dictionary = pickle.load(open(get_dictionary_path(), 'rb'))

    directory_list = [get_malware_directory()] # [get_benign_apps_directory(), get_malware_directory()]

    for i in range(len(directory_list)):
        count = 0

        for path in os.listdir(directory_list[i]):
            count += 1
                
            if count == 34:
                break

            try:
                x = get_compressed_feature_vector(os.path.join(directory_list[i], path), api_call_dictionary)

                data_point = {}
                data_point['x'] = x
                data_point['y'] = 1
                
                # feature_stream = open(os.path.join(get_compressed_features_directories()[0], str(path) + '.save'), 'wb')
                feature_stream = open(os.path.join(get_compressed_features_directories()[1], str(path) + '.save'), 'wb')
                pickle.dump(data_point, feature_stream, protocol = pickle.HIGHEST_PROTOCOL)
                feature_stream.close()	
            except Exception as e:
                log.e('Failed to extract a compressed feature. An exception occurred.\n' + repr(e))


def get_compressed_feature_vector(path, api_call_dictionary):
    '''
    Get a compressed feature vector.

    :param path: the path of the file to get a cpmpressed feature vector
    :param api_call_dictionary: a dictionary of API calls
    :returns: a compressed feature vector
    '''

    max_sequences = 50
    feature_vector = np.zeros((max_calls, max_sequences), dtype = int)

    call_count = 0
    sequence_count = 0

    if path.endswith('.apk'):
        app = apk.APK(path)
        app_dex = dvm.DalvikVMFormat(app.get_dex())
    else: 
        app_dex = dvm.DalvikVMFormat(open(path, 'rb').read())

    app_x = analysis.Analysis(app_dex)
    class_names = [classes.get_name() for classes in app_dex.get_classes()]

    for method in app_dex.get_methods():
        g = app_x.get_method(method)
    
        if method.get_code() == None:
            continue

        for i in g.get_basic_blocks().get():
            if i.childs != [] and sequence_count < max_sequences:
                call_count = 0
                
                for ins in i.get_instructions():
                    output = ins.get_output() # this is a string that contains methods, variables, or anything else
                    match = re.search(r'(L[^;]*;)->[^\(]*\([^\)]*\).*', output)
                    
                    if match and match.group(1) not in class_names and call_count < max_calls:
                        feature_vector[call_count, sequence_count] = api_call_dictionary[match.group()]
                        call_count += 1
                
                rand_child_selected = np.random.randint(len(i.childs))
                traverse_graph(i.childs[rand_child_selected][2], feature_vector, class_names, call_count, sequence_count, api_call_dictionary)
                
                sequence_count += 1

    return feature_vector


def traverse_graph(node,
    feature_vector,
    class_names,
    call_count,
    sequence_count,
    api_call_dictionary):
    '''
    Recursively run the analyser to track different possible execution paths of the code (each run with a different random choice at the
    branching points).

    :param node: a branch
    :param feature_vector: a compressed feature vector
    :param class_names: class names of the file being processed
    :param call_count: the number of calls
    :param sequence_count: the number of sequences
    :param api_call_dictionary: a dictionary of API calls
    '''

    for ins in node.get_instructions():
        output = ins.get_output()
        match = re.search(r'(L[^;]*;)->[^\(]*\([^\)]*\).*', output)

        if match and match.group(1) not in class_names and call_count < max_calls:
            feature_vector[call_count, sequence_count] = api_call_dictionary[match.group()]
            call_count += 1
    
    if node.childs != [] and call_count < max_calls:
        rand_child_selected = np.random.randint(len(node.childs))
        traverse_graph(node.childs[rand_child_selected][2], feature_vector, class_names, call_count, sequence_count, api_call_dictionary)


# test purposes only
if __name__ == '__main__':
    extract_compressed_features()